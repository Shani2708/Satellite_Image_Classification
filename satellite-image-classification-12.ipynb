{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2546969,"sourceType":"datasetVersion","datasetId":1544742}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Tensorflow","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:10.542961Z","iopub.execute_input":"2024-09-02T11:50:10.543831Z","iopub.status.idle":"2024-09-02T11:50:21.848685Z","shell.execute_reply.started":"2024-09-02T11:50:10.543788Z","shell.execute_reply":"2024-09-02T11:50:21.847666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/satellite-image-classification/data/\"\nbatch_size = 32\nheight = 72\nwidth = 128","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:23.818630Z","iopub.execute_input":"2024-09-02T11:50:23.819740Z","iopub.status.idle":"2024-09-02T11:50:23.823883Z","shell.execute_reply.started":"2024-09-02T11:50:23.819700Z","shell.execute_reply":"2024-09-02T11:50:23.822959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading the dataset and splitting into training and validation sets\ntrain = tf.keras.utils.image_dataset_from_directory(\n    path,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1234,\n    image_size=(height, width),\n    batch_size=batch_size)\n\nval = tf.keras.utils.image_dataset_from_directory(\n    path,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1234,\n    image_size=(height, width),\n    batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:34.411318Z","iopub.execute_input":"2024-09-02T11:50:34.412008Z","iopub.status.idle":"2024-09-02T11:50:39.179358Z","shell.execute_reply.started":"2024-09-02T11:50:34.411967Z","shell.execute_reply":"2024-09-02T11:50:39.178623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the first images with their labels\nplt.figure(figsize=(13, 5))\nfor i, (images, labels) in enumerate(train.take(1)):\n    for j in range(9):\n        ax = plt.subplot(3, 3, j + 1)\n        plt.imshow(images[j].numpy().astype(\"uint8\"))\n        plt.title(f\"Label: {labels[j].numpy()}\")\n        plt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:43.707304Z","iopub.execute_input":"2024-09-02T11:50:43.707708Z","iopub.status.idle":"2024-09-02T11:50:44.412433Z","shell.execute_reply.started":"2024-09-02T11:50:43.707670Z","shell.execute_reply":"2024-09-02T11:50:44.411507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {\n    0: \"cloudy\",\n    1: \"desert\",\n    2: \"water\",\n    3: \"green_area\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:47.302730Z","iopub.execute_input":"2024-09-02T11:50:47.303622Z","iopub.status.idle":"2024-09-02T11:50:47.308164Z","shell.execute_reply.started":"2024-09-02T11:50:47.303580Z","shell.execute_reply":"2024-09-02T11:50:47.307034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN model architecture\nmodel = Sequential([\n    layers.Input(shape=(height, width, 3)),\n    layers.Rescaling(1./255),\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(4, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:50.507184Z","iopub.execute_input":"2024-09-02T11:50:50.508139Z","iopub.status.idle":"2024-09-02T11:50:50.604735Z","shell.execute_reply.started":"2024-09-02T11:50:50.508087Z","shell.execute_reply":"2024-09-02T11:50:50.603785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:53.891772Z","iopub.execute_input":"2024-09-02T11:50:53.892728Z","iopub.status.idle":"2024-09-02T11:50:53.907792Z","shell.execute_reply.started":"2024-09-02T11:50:53.892683Z","shell.execute_reply":"2024-09-02T11:50:53.906653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\nhistory = model.fit(\n    train,\n    validation_data=val,\n    epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:50:56.983891Z","iopub.execute_input":"2024-09-02T11:50:56.984547Z","iopub.status.idle":"2024-09-02T11:51:49.596231Z","shell.execute_reply.started":"2024-09-02T11:50:56.984507Z","shell.execute_reply":"2024-09-02T11:51:49.595431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:51:53.780643Z","iopub.execute_input":"2024-09-02T11:51:53.781674Z","iopub.status.idle":"2024-09-02T11:51:53.813367Z","shell.execute_reply.started":"2024-09-02T11:51:53.781624Z","shell.execute_reply":"2024-09-02T11:51:53.812503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy and loss\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(epochs)\n\nplt.figure(figsize=(16, 5))\nplt.plot(epochs_range, accuracy, label='Training Accuracy', color='green')\nplt.plot(epochs_range, val_accuracy, label='Validation Accuracy', color='red')\nplt.legend(loc='lower right')\nplt.title('Accuracy vs Epochs')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:51:57.634276Z","iopub.execute_input":"2024-09-02T11:51:57.634678Z","iopub.status.idle":"2024-09-02T11:51:57.924424Z","shell.execute_reply.started":"2024-09-02T11:51:57.634640Z","shell.execute_reply":"2024-09-02T11:51:57.923499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 5))\nplt.plot(epochs_range, loss, label='Training Loss', color='green')\nplt.plot(epochs_range, val_loss, label='Validation Loss', color='red')\nplt.legend(loc='upper right')\nplt.title('Loss vs Epochs')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:52:45.967670Z","iopub.execute_input":"2024-09-02T11:52:45.968058Z","iopub.status.idle":"2024-09-02T11:52:46.288631Z","shell.execute_reply.started":"2024-09-02T11:52:45.968022Z","shell.execute_reply":"2024-09-02T11:52:46.287741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Pytorch","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:08.420008Z","iopub.execute_input":"2024-09-02T11:53:08.420624Z","iopub.status.idle":"2024-09-02T11:53:08.425204Z","shell.execute_reply.started":"2024-09-02T11:53:08.420582Z","shell.execute_reply":"2024-09-02T11:53:08.424310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/satellite-image-classification/data/\"\nbatch_size = 32\nheight = 72\nwidth = 128\nnum_epochs = 20","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:09.667856Z","iopub.execute_input":"2024-09-02T11:53:09.668245Z","iopub.status.idle":"2024-09-02T11:53:09.672499Z","shell.execute_reply.started":"2024-09-02T11:53:09.668213Z","shell.execute_reply":"2024-09-02T11:53:09.671539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data transforms\ntransform = transforms.Compose([\n    transforms.Resize((height, width)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:14.160046Z","iopub.execute_input":"2024-09-02T11:53:14.160776Z","iopub.status.idle":"2024-09-02T11:53:14.165726Z","shell.execute_reply.started":"2024-09-02T11:53:14.160735Z","shell.execute_reply":"2024-09-02T11:53:14.164696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = datasets.ImageFolder(path, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:17.951261Z","iopub.execute_input":"2024-09-02T11:53:17.951681Z","iopub.status.idle":"2024-09-02T11:53:18.815491Z","shell.execute_reply.started":"2024-09-02T11:53:17.951643Z","shell.execute_reply":"2024-09-02T11:53:18.814508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_set, val_set = random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:20.813184Z","iopub.execute_input":"2024-09-02T11:53:20.813552Z","iopub.status.idle":"2024-09-02T11:53:20.818758Z","shell.execute_reply.started":"2024-09-02T11:53:20.813519Z","shell.execute_reply":"2024-09-02T11:53:20.817838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:53:28.046522Z","iopub.execute_input":"2024-09-02T11:53:28.047363Z","iopub.status.idle":"2024-09-02T11:53:28.053176Z","shell.execute_reply.started":"2024-09-02T11:53:28.047313Z","shell.execute_reply":"2024-09-02T11:53:28.052117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define CNN model\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.relu1 = nn.ReLU()\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.relu2 = nn.ReLU()\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.relu3 = nn.ReLU()\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(64 * (height // 8) * (width // 8), 128)\n        self.relu4 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 4)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.maxpool1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.maxpool2(x)\n        x = self.conv3(x)\n        x = self.relu3(x)\n        x = self.maxpool3(x) \n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.relu4(x)\n        x = self.fc2(x)\n        return x\n\n# Check if CUDA is available and set the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instantiate the model, define the loss function and the optimizer\nmodel_cnn = CNNModel().to(device)  # Move the model to the correct device\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:54:39.556429Z","iopub.execute_input":"2024-09-02T11:54:39.556902Z","iopub.status.idle":"2024-09-02T11:54:39.581665Z","shell.execute_reply.started":"2024-09-02T11:54:39.556854Z","shell.execute_reply":"2024-09-02T11:54:39.580857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and validation loop\nnum_epochs = 20\ntrain_losses_CNN = []\nval_losses_CNN = []\ntrain_accuracies_CNN = []\nval_accuracies_CNN = []\n\nfor epoch in range(num_epochs):\n    model_cnn.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_losses_CNN.append(train_loss)\n    train_accuracy = 100 * correct / total\n    train_accuracies_CNN.append(train_accuracy)\n\n    model_cnn.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_losses_CNN.append(val_loss)\n    val_accuracy = 100 * correct / total\n    val_accuracies_CNN.append(val_accuracy)\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T11:57:43.724473Z","iopub.execute_input":"2024-09-02T11:57:43.724882Z","iopub.status.idle":"2024-09-02T12:01:27.830708Z","shell.execute_reply.started":"2024-09-02T11:57:43.724843Z","shell.execute_reply":"2024-09-02T12:01:27.829724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Plot the training and validation loss\nplt.figure(figsize=(8, 6))\n\nplt.plot(range(1, num_epochs + 1), train_losses_CNN, label='Training Loss')\nplt.plot(range(1, num_epochs + 1), val_losses_CNN, label='Validation Loss')\nplt.title('Loss vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:09:44.943112Z","iopub.execute_input":"2024-09-02T12:09:44.943525Z","iopub.status.idle":"2024-09-02T12:09:45.252115Z","shell.execute_reply.started":"2024-09-02T12:09:44.943481Z","shell.execute_reply":"2024-09-02T12:09:45.251124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation accuracy\nplt.figure(figsize=(7, 5))\n\nplt.plot(range(1, num_epochs + 1), train_accuracies_CNN, label='Training Accuracy')\nplt.plot(range(1, num_epochs + 1), val_accuracies_CNN, label='Validation Accuracy')\nplt.title('Accuracy vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:11:14.564256Z","iopub.execute_input":"2024-09-02T12:11:14.564660Z","iopub.status.idle":"2024-09-02T12:11:14.805382Z","shell.execute_reply.started":"2024-09-02T12:11:14.564621Z","shell.execute_reply":"2024-09-02T12:11:14.804331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"**ResNET50**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import models, transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:05:23.507177Z","iopub.execute_input":"2024-09-02T13:05:23.507579Z","iopub.status.idle":"2024-09-02T13:05:28.900259Z","shell.execute_reply.started":"2024-09-02T13:05:23.507515Z","shell.execute_reply":"2024-09-02T13:05:28.899457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.RandomResizedCrop((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:05:33.979194Z","iopub.execute_input":"2024-09-02T13:05:33.980021Z","iopub.status.idle":"2024-09-02T13:05:33.985705Z","shell.execute_reply.started":"2024-09-02T13:05:33.979976Z","shell.execute_reply":"2024-09-02T13:05:33.984552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = ImageFolder('/kaggle/input/satellite-image-classification/data/', transform=transform)\ntest_size = 0.2\nnum_dataset = len(dataset)\nnum_test = int(num_dataset * test_size)\nnum_train = num_dataset - num_test","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:06:16.877573Z","iopub.execute_input":"2024-09-02T13:06:16.878302Z","iopub.status.idle":"2024-09-02T13:06:19.458658Z","shell.execute_reply.started":"2024-09-02T13:06:16.878260Z","shell.execute_reply":"2024-09-02T13:06:19.457597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, test_set = random_split(dataset, [num_train, num_test])\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:06:23.072658Z","iopub.execute_input":"2024-09-02T13:06:23.073059Z","iopub.status.idle":"2024-09-02T13:06:23.107761Z","shell.execute_reply.started":"2024-09-02T13:06:23.073019Z","shell.execute_reply":"2024-09-02T13:06:23.106951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained ResNet50 model\nmodel = models.resnet50(pretrained=True)\n\n# Modify the final layer to match the number of classes in your dataset\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 4)  # Assuming 4 classes\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:12:00.129299Z","iopub.execute_input":"2024-09-02T12:12:00.129598Z","iopub.status.idle":"2024-09-02T12:12:00.684110Z","shell.execute_reply.started":"2024-09-02T12:12:00.129565Z","shell.execute_reply":"2024-09-02T12:12:00.682926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and validation loop\nnum_epochs = 10\ntrain_losses_res = []\nval_losses_res = []\ntrain_accuracies_res = []\nval_accuracies_res = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_losses_res.append(train_loss)\n    train_accuracy = 100 * correct / total\n    train_accuracies_res.append(train_accuracy)\n\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= len(test_loader)\n    val_losses_res.append(val_loss)\n    val_accuracy = 100 * correct / total\n    val_accuracies_res.append(val_accuracy)\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:13:20.702436Z","iopub.execute_input":"2024-09-02T12:13:20.703281Z","iopub.status.idle":"2024-09-02T12:23:35.247399Z","shell.execute_reply.started":"2024-09-02T12:13:20.703242Z","shell.execute_reply":"2024-09-02T12:23:35.246431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:33:52.254628Z","iopub.execute_input":"2024-09-02T13:33:52.254994Z","iopub.status.idle":"2024-09-02T13:33:52.259657Z","shell.execute_reply.started":"2024-09-02T13:33:52.254960Z","shell.execute_reply":"2024-09-02T13:33:52.258374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.figure(figsize=(10, 5))\n\n# Plot training loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, num_epochs + 1), train_losses_res, label='Training Loss')\nplt.plot(range(1, num_epochs + 1), val_losses_res, label='Validation Loss')\nplt.title('Loss vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs + 1), train_accuracies_res, label='Training Accuracy')\nplt.plot(range(1, num_epochs + 1), val_accuracies_res, label='Validation Accuracy')\nplt.title('Accuracy vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:58:49.220854Z","iopub.execute_input":"2024-09-02T12:58:49.221604Z","iopub.status.idle":"2024-09-02T12:58:49.716897Z","shell.execute_reply.started":"2024-09-02T12:58:49.221562Z","shell.execute_reply":"2024-09-02T12:58:49.715997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**VGG16**","metadata":{}},{"cell_type":"code","source":"# Load pre-trained VGG16 model\nmodel_vgg16 = models.vgg16(pretrained=True)\n\n# Modify the classifier layer to match the number of classes (4 in this case)\nmodel_vgg16.classifier[6] = nn.Linear(model_vgg16.classifier[6].in_features, 4)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_vgg16 = model_vgg16.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_vgg16.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:06:30.135149Z","iopub.execute_input":"2024-09-02T13:06:30.135693Z","iopub.status.idle":"2024-09-02T13:06:35.049414Z","shell.execute_reply.started":"2024-09-02T13:06:30.135636Z","shell.execute_reply":"2024-09-02T13:06:35.048578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training and validation loop\nnum_epochs = 10\ntrain_losses_vg = []\nval_losses_vg = []\ntrain_accuracies_vg = []\nval_accuracies_vg = []\n\nfor epoch in range(num_epochs):\n    model_vgg16.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model_vgg16(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_losses_vg.append(train_loss)\n    train_accuracy = 100 * correct / total\n    train_accuracies_vg.append(train_accuracy)\n\n    model_vgg16.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model_vgg16(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    val_loss /= len(test_loader)\n    val_losses_vg.append(val_loss)\n    val_accuracy = 100 * correct / total\n    val_accuracies_vg.append(val_accuracy)\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:07:46.639480Z","iopub.execute_input":"2024-09-02T13:07:46.640176Z","iopub.status.idle":"2024-09-02T13:22:47.475415Z","shell.execute_reply.started":"2024-09-02T13:07:46.640134Z","shell.execute_reply":"2024-09-02T13:22:47.474465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training and validation loss\nplt.figure(figsize=(10, 5))\n\n# Plot training loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, num_epochs + 1), train_losses_vg, label='Training Loss')\nplt.plot(range(1, num_epochs + 1), val_losses_vg, label='Validation Loss')\nplt.title('Loss vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, num_epochs + 1), train_accuracies_vg, label='Training Accuracy')\nplt.plot(range(1, num_epochs + 1), val_accuracies_vg, label='Validation Accuracy')\nplt.title('Accuracy vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Show the plots\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-02T13:34:00.006426Z","iopub.execute_input":"2024-09-02T13:34:00.006881Z","iopub.status.idle":"2024-09-02T13:34:00.714043Z","shell.execute_reply.started":"2024-09-02T13:34:00.006838Z","shell.execute_reply":"2024-09-02T13:34:00.712997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}